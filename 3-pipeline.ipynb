{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ee19644a-1ce5-47e4-89e7-46ff622ce1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import operator as op\n",
    "import re\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Custom Transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1ddeabda-a6d6-4bff-aabe-d9f3bd4f1a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/listings.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "470ac0cd-2633-49df-a6a3-5bd6e9076484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnDroppersTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - ColumnDroppersTransformer\")\n",
    "        \n",
    "        # Find features related to host, id and url\n",
    "        re_drop = \".*host.*|.*id.*|.*url.*\"\n",
    "        drop_feat = []\n",
    "        for feat in X.columns:\n",
    "            if re.match(re_drop, feat):\n",
    "                 drop_feat.append(feat)\n",
    "        # Add extra features that for sure will not ber part of the model\n",
    "        drop_feat.extend([\"calendar_updated\", \"license\", \"neighbourhood_group_cleansed\",\"neighbourhood_cleansed\", \"neighbourhood\", \"neighborhood_overview\", \n",
    "                          \"last_scraped\", \"source\", \"first_review\", \"last_review\", \"name\", \"number_of_reviews_l30d\", \"number_of_reviews\",\n",
    "                          \"availability_30\",\"availability_60\",\"availability_90\", \"minimum_nights\", \"maximum_nights\", \"review_scores_value\",  \n",
    "                         \"review_scores_accuracy\", \"review_scores_rating\", \"review_scores_checkin\", \"review_scores_cleanliness\", \"review_scores_communication\",\n",
    "                         \"has_availability\", \"instant_bookable\", \"calendar_last_scraped\", 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', \n",
    "                          'maximum_maximum_nights', 'maximum_nights_avg_ntm', 'property_type'])\n",
    "        \n",
    "        X = X.drop(drop_feat, axis = 1)\n",
    "        \n",
    "        print(\"End - ColumnDroppersTransformer\")\n",
    "        \n",
    "        print(X.columns)\n",
    "        #print(X.room_type.unique())\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "class DropNasTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - DropNasTransformer\")\n",
    "        \n",
    "        \n",
    "        X = X.dropna(subset = self.features)\n",
    "        \n",
    "        print(type(X))\n",
    "        print(\"End - DropNasTransformer\")\n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_limit, mode = \"remove\", operator = \"eq\"): #st: smaller then\n",
    "                    \n",
    "        self.opt_dict = {\n",
    "        \"lt\":op.lt,\n",
    "        \"le\":op.le,\n",
    "        \"eq\":op.eq,\n",
    "        \"ne\":op.ne,\n",
    "        \"ge\":op.ge,\n",
    "        \"gt\":op.gt,\n",
    "        }    \n",
    "        \n",
    "        self.features_limit = features_limit # list of tuples\n",
    "        self.mode = mode  #mode of operation (cap value or remove value)\n",
    "        self.operator = operator #lt, eq, gt, ...\n",
    "     \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - OutlierRemover\")\n",
    "\n",
    "        \n",
    "        \n",
    "        NAME = 0\n",
    "        LIMIT = 1\n",
    "        REPLACE_VALUE = 2\n",
    "        for a_feature in self.features_limit:\n",
    "            if(self.mode == \"remove\"): ###!!! check if it works\n",
    "                X = X.drop(X[self.opt_dict[self.operator](X[a_feature[NAME]], a_feature[LIMIT])].index, axis = 0)\n",
    "            elif(self.mode == \"cap\"):\n",
    "                X[a_feature[NAME]] =  X[a_feature[NAME]].apply(lambda x : x if self.opt_dict[self.operator](x,a_feature[LIMIT]) else a_feature[LIMIT])\n",
    "            elif(self.mode == \"replace\"):\n",
    "                X[a_feature[NAME]] =  X[a_feature[NAME]].apply(lambda x : a_feature[REPLACE_VALUE] if self.opt_dict[self.operator](x,a_feature[LIMIT]) else x)\n",
    "        \n",
    "\n",
    "        #print(X.room_type.unique())\n",
    "        #input()\n",
    "        \n",
    "        print(\"End - OutlierRemover\")\n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "        \n",
    "        \n",
    "class ClusterGeolocationTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, clusters = 8, init = 'k-means++', n_init = 'auto', max_iter = 300):\n",
    "        \n",
    "        self.clusters = clusters\n",
    "        self.init = init\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - ClusterGeolocationTransformer\")\n",
    "        \n",
    "        # Initialize the model\n",
    "        k_means = KMeans(\n",
    "            init = self.init,\n",
    "            n_clusters = self.clusters,\n",
    "            n_init = self.n_init,\n",
    "            max_iter = self.max_iter,\n",
    "            random_state = 69\n",
    "        )\n",
    "\n",
    "\n",
    "        #Select the data to be clustered\n",
    "        df_kmeans = X.loc[:,[\"latitude\", \"longitude\"]]\n",
    "\n",
    "        # Fitting\n",
    "        k_means.fit(df_kmeans)\n",
    "\n",
    "        #Clusters as a feature\n",
    "        X['geo_cluster'] = k_means.labels_ \n",
    "        #X['geo_cluster'] = X['geo_cluster'].astype(\"str\") # Probably not needed (!) - checkc\n",
    "\n",
    "        ## Encode here\n",
    "        \n",
    "        onehot_encoder_cluster = OneHotEncoder(sparse_output = False, feature_name_combiner='concat')\n",
    "        series_cluster_onehot = onehot_encoder_cluster.fit_transform(X[[\"geo_cluster\"]])\n",
    "        encoded_cat_str = [str(x) for x in onehot_encoder_cluster.categories_[0]]\n",
    "        X[encoded_cat_str] = series_cluster_onehot\n",
    "        X = X.drop(\"geo_cluster\", axis = 1)\n",
    "    \n",
    "        \n",
    "        #Drop latitude and longitude as they will not be fed into the model\n",
    "        X = X.drop([\"longitude\", \"latitude\"], axis = 1)\n",
    "        \n",
    "        \n",
    "        print(\"End - ClusterGeolocationTransformer\")\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "class PreprocessCorpus(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, corpus_feature):\n",
    "        self.corpus_feature = corpus_feature\n",
    "\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - PreprocessCorpus\")\n",
    "        \n",
    "        \n",
    "        def process_corpus(corpus):\n",
    "            \n",
    "            corpus = corpus.lower()\n",
    "            corpus = re.sub(r'[^a-zA-Z ]', ' ', corpus)\n",
    "            corpus = re.sub(r'\\b(the|and|in|with|to|a|of|br|is|from|for|on|this|you|it|has|all|at|de|by|br)\\b', ' ', corpus)\n",
    "            corpus = re.sub(r'br\\b', '', corpus)\n",
    "            return corpus\n",
    "    \n",
    "        X[self.corpus_feature] = X[self.corpus_feature].apply(lambda x : process_corpus(x))\n",
    "        \n",
    "        print(\"End - PreprocessCorpus\")\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self    \n",
    "\n",
    "\n",
    "class ContainWordsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, words, new_feature_name, corpus_target):\n",
    "        self.words = words\n",
    "        self.new_feature_name = new_feature_name\n",
    "        self.corpus_target = corpus_target\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - ContainWordsTransformer\")\n",
    "        \n",
    "        def check_lux_corpus(x):\n",
    "            \n",
    "            # Transform list of words in regex\n",
    "            words_str = \"\"\n",
    "            for i in self.words:\n",
    "                words_str += words_str + i + \"|\"\n",
    "            #remove last \"|\"\n",
    "            words_str =  words_str[:-1] \n",
    "            regex = r'\\b('+words_str+')\\b'\n",
    "            \n",
    "            # Return if description contains lux word or not\n",
    "            if (re.search(regex, x)):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        #Create the feature that identify a property as luxurious\n",
    "        X[self.new_feature_name] = X[self.corpus_target].apply(check_lux_corpus)\n",
    "        \n",
    "        # Drop corpus target feature\n",
    "        X = X.drop(self.corpus_target, axis = 1)\n",
    "        \n",
    "        print(\"End - ContainWordsTransformer\")\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "class ExtractAmenitiesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, amenities_dict):\n",
    "        self.amenities_dict = amenities_dict\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - ExtractAmenitiesTransformer\")\n",
    "        \n",
    "        #This function will check the presence of the amenities in the list using regex\n",
    "        def convert_amenities(amenities, index): \n",
    "            for amn_name, amn_re in self.amenities_dict.items():\n",
    "                if(isinstance(amn_re,list)):\n",
    "                    # Check each reg from the list of reg for an specific amenity. Ex (\"seaview\" : [\".*beach view.*\",\".*sea view.*\",\".*ocean view.*\"])\n",
    "                    for reg in amn_re:\n",
    "                        if(re.match(reg, str.lower(amenities))):\n",
    "                            X.loc[index, \"has_\"+ amn_name] = 1\n",
    "                else:\n",
    "                    if(re.match(amn_re, str.lower(amenities))):\n",
    "                        X.loc[index,\"has_\"+ amn_name] = 1\n",
    "        \n",
    "        # 1) Create and initalize the features from the amenities list\n",
    "        has_amn_feat = [\"has_\" + x for x in self.amenities_dict.keys()]\n",
    "        X[has_amn_feat] = 0\n",
    "        \n",
    "        # 2) For each amenities' list, check if they contain the amenities target\n",
    "        for index, row in X.iterrows():\n",
    "            convert_amenities(X.loc[index, \"amenities\"], index)\n",
    "        \n",
    "        # 3) Drop 'amenities' feature\n",
    "        X = X.drop(\"amenities\", axis = 1)\n",
    "        \n",
    "        print(\"End - ExtractAmenitiesTransformer\")\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "class ExtractBathroom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        print(\"Start - ExtractBathroom\")\n",
    "        \n",
    "        def bathroom_number(a_bath):\n",
    "            \n",
    "            is_shared = 0 #default value\n",
    "\n",
    "            # Case if it is a missing value\n",
    "            if(pd.isna(a_bath)):\n",
    "                number_bath = np.nan\n",
    "                is_shared = np.nan\n",
    "                \n",
    "            # Check if bathroom is shared using regex\n",
    "            else:\n",
    "                if(re.match(\".*shared.*\", str.lower(a_bath))):\n",
    "                        is_shared = 1  \n",
    "\n",
    "\n",
    "            return is_shared\n",
    "            \n",
    "    \n",
    "\n",
    "        X[[\"is_bathroom_shared\"]] = X[\"bathrooms_text\"].apply(lambda x: pd.Series(bathroom_number(x)))\n",
    "        \n",
    "        X = X.drop(\"bathrooms_text\", axis = 1)\n",
    "        \n",
    "        print(\"End - ExtractBathroom\")\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class CatImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_limits):\n",
    "        self.features_limits = features_limits\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - CatImputer\")\n",
    "        \n",
    "        FILL_VALUE = 1\n",
    "        FEATURE = 0\n",
    "        X_imp = X\n",
    "        for feat in self.features_limits:\n",
    "            imp = SimpleImputer(strategy='constant', fill_value= feat[FILL_VALUE])\n",
    "            X_imp = imp.fit_transform(X_imp)\n",
    "        \n",
    "        print(\"End - CatImputer\")\n",
    "        \n",
    "        return pd.DataFrame(X_imp, columns = X.columns)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self  \n",
    "    \n",
    "\n",
    "class NumImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - FeaturesImputer\")\n",
    "        \n",
    "        num_ft = X.select_dtypes(exclude = 'object').columns\n",
    "        for a_ft in num_ft:\n",
    "            X.loc[:, a_ft] = X[a_ft].fillna(0)\n",
    "        \n",
    "        print(\"End - FeaturesImputer\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "class ColumnTransformerDF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, transformers):\n",
    "        self.transformers = transformers\n",
    "        self.ct = None\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        #Retain the feature name and order\n",
    "        self.ct = ColumnTransformer(self.transformers)\n",
    "        self.ct.fit(X) \n",
    "        self.feature_names = self.ct.get_feature_names_out()\n",
    "        \n",
    "        return self  \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_ct = ct.transform(X)\n",
    "        return pd.DataFrame(X_ct, columns = self.feature_names)\n",
    "    \n",
    "    \n",
    "    \n",
    "class TypeConversionTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_to_type_list):\n",
    "        self.feature_to_type_list = feature_to_type_list\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "    \n",
    "        \n",
    "        print(\"Start - TypeConversionTransformer\")\n",
    "        \n",
    "        for feature, new_type in self.feature_to_type_list:\n",
    "            X.loc[:,feature] = X[feature].astype(new_type)\n",
    "        \n",
    "        \n",
    "        print(\"End - TypeConversionTransformer\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "class FeatureEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_list):\n",
    "        self.features_list = features_list\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "    \n",
    "        \n",
    "        print(\"Start - FeatureEncoding\")\n",
    "        \n",
    "        for feature in self.features_list:    \n",
    "            ## Encode here\n",
    "\n",
    "            onehote_encoder = OneHotEncoder(sparse_output = False, feature_name_combiner='concat')\n",
    "            series_onehot = onehote_encoder.fit_transform(X[[feature]])\n",
    "            encoded_str = [str(x) for x in onehote_encoder.categories_[0]]\n",
    "            X[encoded_str] = series_onehot\n",
    "            X = X.drop(feature, axis = 1)\n",
    "        \n",
    "        print(\"End - FeatureEncoding\")\n",
    "        \n",
    "        #print(X.columns)\n",
    "        #print(X.shape)\n",
    "        #input()\n",
    "        \n",
    "    \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e8f68edc-c923-4ab5-8ee8-167413e37a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feature = \"price\"\n",
    "\n",
    "###########################\n",
    "# PREPROCESSING TARGET FT #\n",
    "###########################\n",
    "\n",
    "# Dropping 'na' for prices\n",
    "df = df.dropna(subset = \"price\")\n",
    "\n",
    "# Convert prices to numerical value\n",
    "df[\"price\"] = df[\"price\"].apply(lambda x: float(x[1:].replace(\",\",\"\")) if pd.notna(x) else x)\n",
    "\n",
    "PRICE_CAP = 1000\n",
    "# Cap price outliers\n",
    "df[\"price\"] = df[\"price\"].apply(lambda x : x if x < PRICE_CAP else PRICE_CAP)\n",
    "\n",
    "########################\n",
    "# PIPELINE PREPARATION #\n",
    "########################\n",
    "\n",
    "# Separte target feature from the dataset\n",
    "X = df.drop(target_feature, axis = 1)\n",
    "y = df[target_feature]\n",
    "\n",
    "\n",
    "#############\n",
    "# PIPELINE  #\n",
    "#############\n",
    "\n",
    "\n",
    "num_feat_extraction_pipeline = Pipeline([\n",
    "    (\"clusterlocation\", ClusterGeolocationTransformer(clusters = 25, init = \"random\", n_init = 15, max_iter = 1000)),\n",
    "    \n",
    "       \n",
    "    # binary is_score_empty (?) - maybe info is reduntant\n",
    "])\n",
    "\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "cat_feat_extraction_pipeline = Pipeline([\n",
    "    #Removes capital letters, ponctuation, etc...\n",
    "    (\"preprocesstext\", PreprocessCorpus(\"description\")),\n",
    "     #Creates a new feature based on lux words\n",
    "    (\"extractluxdescription\", ContainWordsTransformer(new_feature_name = \"contains_lux_description\", \n",
    "                                               corpus_target = \"description\",\n",
    "                                               words = [\"lux\",\"luxurious\",\"luxury\",\"fancy\",\"garage\", \n",
    "                                                  \"hydromassage\", \"cellar\", \"sophistication\", \n",
    "                                                  \"magnificent\", \"colonial\", \"rooftop\", \"triplex\", \"suite\"])), \n",
    "    \n",
    "    (\"extractamenities\", ExtractAmenitiesTransformer(\n",
    "                                                { \"parking\": \".*parking on premises.*\",\n",
    "                                                  \"pool\":\".*pool.*(?!.*\\btable\\b).*\",\n",
    "                                                  \"washer\": \".*washer.*\",\n",
    "                                                  \"dishwasher\": \".*dishwasher.*\",\n",
    "                                                 \"ceiling_fan\" : \".*ceiling fan.*\",\n",
    "                                                 \"long_term\" : \".*long term.*\",\n",
    "                                                 \"bbq_grill\" : \".*bbq grill.*\",\n",
    "                                                 \"outdoor\": \".*outdoor.*\",\n",
    "                                                 \"hot_tub\": \".*hot tub.*\",\n",
    "                                                 \"bathtub\": \".*bathtub.*\",\n",
    "                                                 \"ac\": [\".*air conditioning.*\",\"\\\\bac\\\\b\"],\n",
    "                                                 \"seaview\" : [\".*beach view.*\",\".*sea view.*\",\".*ocean view.*\"]\n",
    "                                                }\n",
    "    )),\n",
    "    \n",
    "    (\"extractbathroom\", ExtractBathroom()),\n",
    "    #(\"extractroomtype\", OneHotEncoder(sparse_output = False, feature_name_combiner='concat')),\n",
    "])\n",
    "\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"num_imputer\", NumImputer(value = 0)),\n",
    "    (\"outliers\", OutlierRemover(\n",
    "                                features_limit = [\n",
    "                                                 (\"minimum_nights_avg_ntm\", 7),\n",
    "                                                 (\"beds\", 8),\n",
    "                                                 (\"bedrooms\", 5),\n",
    "                                                 (\"bathrooms\", 5),\n",
    "                                                 (\"accommodates\", 10),\n",
    "                                                 (\"number_of_reviews_ltm\", 25),\n",
    "                                                 (\"reviews_per_month\", 4),\n",
    "                                                ],\n",
    "                                mode = \"cap\",\n",
    "                                operator = \"lt\" #operation: less then (lt)\n",
    "                                \n",
    "                                )),\n",
    "    \n",
    "])\n",
    "\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"cat_imputer\", CatImputer(\n",
    "                            features_limits = [(\"bathroom_text\", \"Private bath\"),\n",
    "                                               (\"description\", \"\"),\n",
    "                                              ]\n",
    "    )),\n",
    "    (\"outliers\", OutlierRemover(\n",
    "                                features_limit = [(\"room_type\", \"Hotel room\", \"Private room\")], #Replace 'Hotel room' by 'Private room'\n",
    "                                mode = \"replace\",\n",
    "                                operator = \"eq\",\n",
    "    )),\n",
    "\n",
    "])\n",
    "\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "\n",
    "preprocessor_pipeline = Pipeline([   \n",
    "      \n",
    "    #Imputers\n",
    "    (\"num_imputer\", NumImputer(value = 0)),\n",
    "    (\"cat_imputer\", CatImputer(\n",
    "                            features_limits = [(\"bathroom_text\", \"Private bath\"),\n",
    "                                               (\"description\", \"\"),\n",
    "                                              ])),\n",
    "    #Outliers\n",
    "    (\"num_outliers\", OutlierRemover(\n",
    "                                features_limit = [\n",
    "                                                 (\"minimum_nights_avg_ntm\", 7),\n",
    "                                                 (\"beds\", 8),\n",
    "                                                 (\"bedrooms\", 5),\n",
    "                                                 (\"bathrooms\", 5),\n",
    "                                                 (\"accommodates\", 10),\n",
    "                                                 (\"number_of_reviews_ltm\", 25),\n",
    "                                                 (\"reviews_per_month\", 4),\n",
    "                                                ],\n",
    "                                mode = \"cap\",\n",
    "                                operator = \"lt\" #operation: less then (lt)\n",
    "                                \n",
    "                                )),\n",
    "    \n",
    "     (\"cat_outliers\", OutlierRemover(\n",
    "                                features_limit = [(\"room_type\", \"Hotel room\", \"Private room\")], #Replace 'Hotel room' by 'Private room'\n",
    "                                mode = \"replace\",\n",
    "                                operator = \"eq\",\n",
    "    )),\n",
    "    \n",
    "    \n",
    "    #Encoding Feature\n",
    "    (\"cat_encoding\", FeatureEncoding([\"room_type\"]))\n",
    "])\n",
    "\n",
    "\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "#onehotencoder = ColumnTransformer([\"onehotencoder\",\n",
    "#                                          OneHotEncoder(sparse_output = False, feature_name_combiner='concat'),\n",
    "#                                          X.select_dtypes(include = \"object\")])\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    # Outliers, Nas\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    \n",
    "    # Feature Extraction\n",
    "    (\"num_feature_extraction\", num_feat_extraction_pipeline),\n",
    "    (\"cat_feat_extraction_pipeline\", cat_feat_extraction_pipeline),   \n",
    "    \n",
    "    # Feature Selection\n",
    "    ('columndrop', ColumnDroppersTransformer()), \n",
    "\n",
    "    #Normalisation\n",
    "    (\"normalisation\", MinMaxScaler()),\n",
    "\n",
    "    \n",
    "])\n",
    "\n",
    "##################################\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3efe9ed7-db4a-4625-ae42-6700e0b1aeb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start - FeaturesImputer\n",
      "End - FeaturesImputer\n",
      "Start - CatImputer\n",
      "End - CatImputer\n",
      "Start - OutlierRemover\n",
      "End - OutlierRemover\n",
      "Start - OutlierRemover\n",
      "End - OutlierRemover\n",
      "Start - FeatureEncoding\n",
      "End - FeatureEncoding\n",
      "Start - ClusterGeolocationTransformer\n",
      "End - ClusterGeolocationTransformer\n",
      "Start - PreprocessCorpus\n",
      "End - PreprocessCorpus\n",
      "Start - ContainWordsTransformer\n",
      "End - ContainWordsTransformer\n",
      "Start - ExtractAmenitiesTransformer\n",
      "End - ExtractAmenitiesTransformer\n",
      "Start - ExtractBathroom\n",
      "End - ExtractBathroom\n",
      "Start - ColumnDroppersTransformer\n",
      "End - ColumnDroppersTransformer\n",
      "Index(['accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
      "       'minimum_nights_avg_ntm', 'availability_365', 'number_of_reviews_ltm',\n",
      "       'review_scores_location', 'reviews_per_month', 'Entire home/apt',\n",
      "       'Private room', 'Shared room', '0', '1', '2', '3', '4', '5', '6', '7',\n",
      "       '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19',\n",
      "       '20', '21', '22', '23', '24', 'contains_lux_description', 'has_parking',\n",
      "       'has_pool', 'has_washer', 'has_dishwasher', 'has_ceiling_fan',\n",
      "       'has_long_term', 'has_bbq_grill', 'has_outdoor', 'has_hot_tub',\n",
      "       'has_bathtub', 'has_ac', 'has_seaview', 'is_bathroom_shared'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "X_final = model_pipeline.fit_transform(X)\n",
    "\n",
    "#Predict\n",
    "#pred = model_pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a29eb-8549-4420-a27e-d6bb5237915c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ea6ac581-b957-4bc8-9f69-c0a7192a1b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33692, 51)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3c401904-f052-4dc1-8e3d-b1f1f6a7836d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44444444, 0.2       , 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.22222222, 0.2       , 0.2       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11111111, 0.2       , 0.2       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.22222222, 0.4       , 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.22222222, 0.3       , 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11111111, 0.2       , 0.2       , ..., 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "224e97ce-af67-495f-be09-0e88a51d3105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0d056dda-2fcf-472f-bcaf-b49375b0036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size = 0.25, random_state = 70)\n",
    "\n",
    "\n",
    "hgbr = HistGradientBoostingRegressor(random_state = 69)\n",
    "\n",
    "\n",
    "\n",
    "hgbr.fit(X_train, y_train)\n",
    "y_pred = hgbr.predict(X_test)\n",
    "\n",
    "\n",
    "# Calclulate the score for the following metrics\n",
    "mae = mean_absolute_error(y_test, y_pred) #The lower the better\n",
    "rmse = root_mean_squared_error(y_test, y_pred) #The lower the better\n",
    "r2 = r2_score(y_test, y_pred) #Closer to 1 better\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "c54a18b3-3a0e-4fbb-9091-dacb67b2c80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = [r2, mape, mae, rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "cc91b37a-8e83-47ab-8317-2ae921990a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.616304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmse</td>\n",
       "      <td>181.133114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mae</td>\n",
       "      <td>127.898158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mape</td>\n",
       "      <td>0.403832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1\n",
       "0    r2    0.616304\n",
       "1  rmse  181.133114\n",
       "2   mae  127.898158\n",
       "3  mape    0.403832"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1507a7c-d13e-4de9-9ed4-d88e03180155",
   "metadata": {},
   "source": [
    "class PriceTypeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        print(\"Start - PriceTypeTransformer - transform\")\n",
    "        \n",
    "        X[\"price\"] = X[\"price\"].apply(lambda x: float(x[1:].replace(\",\",\"\")) if pd.notna(x) else x)\n",
    "        \n",
    "        print(\"End - PriceTypeTransformer - transform\")\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7eeaa-3deb-4126-bda8-28de2a4f6577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4fc71-5aee-429d-8265-a6b0644811ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4226147-3b84-4df1-a5e3-6616f7af6321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Custom transformers (for template purposes of how pipeline works)\n",
    "\n",
    "#Drop columns\n",
    "class ColumnDropperTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.drop(self.columns, axis = 1)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "#Filter\n",
    "class DropNas(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.dropna(subset = \"bathrooms\")\n",
    "        X = X.dropna(subset = [\"bedrooms\", \"beds\"])\n",
    "        #X = X.dropna(subset = \"price\")\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9afcc-ec8d-4e42-92a0-db78a49fa474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_columns = [\"host_id\", \"host_url\", \"host_name\", \"host_location\", \"host_about\", \"host_thumbnail_url\", \n",
    "        \"host_picture_url\", \"host_neighbourhood\", \"host_since\", \"host_listings_count\", \"host_total_listings_count\",\n",
    "        \"id\", \"scrape_id\", \"listing_url\", \"picture_url\", \"minimum_minimum_nights\", \"maximum_minimum_nights\", \"minimum_maximum_nights\", \n",
    "        \"maximum_maximum_nights\", \"minimum_nights_avg_ntm\", \"maximum_nights_avg_ntm\", \"last_scraped\", \"source\", \"first_review\", \"last_review\", \"license\", \"neighbourhood\",\n",
    "        \"neighborhood_overview\", \"neighbourhood_group_cleansed\", \"name\", \"description\",\n",
    "        \"calendar_updated\", \"calculated_host_listings_count\", \"calculated_host_listings_count_entire_homes\",\n",
    "        \"calculated_host_listings_count_private_rooms\", \"calculated_host_listings_count_shared_rooms\", \"calendar_last_scraped\", \"longitude\", \"latitude\",\"availability_365\", \"minimum_nights\", \n",
    "        \"maximum_nights\", \"availability_30\",\"availability_60\", \"availability_90\", \"number_of_reviews_ltm\", \"number_of_reviews_l30d\", \"number_of_reviews\",\n",
    "               \"review_scores_value\", \"review_scores_rating\", \"review_scores_accuracy\",\n",
    "               \"review_scores_checkin\", \"review_scores_cleanliness\", \"review_scores_communication\",\n",
    "               \"review_scores_location\" ,\"reviews_per_month\", \"has_availability\", \"instant_bookable\", \"host_response_rate\", \"host_acceptance_rate\", \"host_is_superhost\", \"host_has_profile_pic\", \"host_identity_verified\",\n",
    "                \"host_response_time\", \"property_type\", \"host_verifications\"\n",
    "                \n",
    "                \n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c28053-d21e-4d16-a151-1f52f2eb7995",
   "metadata": {
    "tags": []
   },
   "source": [
    "drop_transformer = ColumnDropperTransformer(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213379b-ad18-4bc6-b36a-6bb5911896ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "df_transformed = drop_transformer.fit_transform(df)\n",
    "print(df_transformed.isna().sum())\n",
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9d188-04c8-4a4d-b919-05a944853be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Option 1: Naming the transformers\n",
    "my_pipeline_named = Pipeline([\n",
    "    (\"dropnas\", DropNas()),\n",
    "    (\"dropcolumns\", ColumnDropperTransformer(columns = drop_columns)),\n",
    "])\n",
    "\n",
    "#Option 2: NOT naming the transformers\n",
    "my_pipeline_unamed = make_pipeline(DropNas(), \n",
    "                            ColumnDropperTransformer(columns = drop_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5163cbb-bf72-465c-9e44-ef5fa6383273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = my_pipeline_named.fit_transform(df)\n",
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d7ffd-8aa8-4e35-ba8d-cefbc00b70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implement the idea of the code bellow where we separate ccategorical and numerical data and apply5 different transofrmes to each (!)\n",
    "using ColumnTransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49924cf2-fda2-434a-8eee-908dadcf66f0",
   "metadata": {},
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\",\n",
    "               \"total_bedrooms\", \"population\", \"households\", \"median_income\"]\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0842ec5a-99bf-49c2-820b-3389d8a3b2b6",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90545dc9-327f-47fe-945d-cbcb41d112ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "re_drop = \".*host.*|.*id.*|.*url.*\"\n",
    "\n",
    "drop_feat = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    if re.match(re_drop, feat):\n",
    "         drop_feat.append(feat)\n",
    "            \n",
    "drop_feat.extend([\"calendar_updated\", \"license\", \"neighbourhood_group_cleansed\", \"neighbourhood\", \"neighborhood_overview\", \"last_scraped\", \"source\", \"first_review\", \"last_review\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed6fea-5f28-4ee6-b4a0-7f04c9a6ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
